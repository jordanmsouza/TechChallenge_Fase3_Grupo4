{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYvpDCGfiheqtCtbJcpLJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jordanmsouza/TechChallenge_Fase3_Grupo4/blob/develop/TechChallenge_Fase3_Grupo4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montando o Drive"
      ],
      "metadata": {
        "id": "RpEBdCVtVEiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ydzymi5AVDXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação de dependências:"
      ],
      "metadata": {
        "id": "rkafwfmFUQTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RyeyNEVTxJx"
      },
      "outputs": [],
      "source": [
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install triton\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install transformers datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importando Bibliotecas"
      ],
      "metadata": {
        "id": "Kh9T6w2H7L4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "NCivTz3L7IAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações do modelo para fine-tuning"
      ],
      "metadata": {
        "id": "oIIQua-M_uKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length = 2048\n",
        "dtype = None\n",
        "load_in_4bit = True"
      ],
      "metadata": {
        "id": "CIisQbWQ_tsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelos Compativeis"
      ],
      "metadata": {
        "id": "sXGtKSdjAc6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B\",\n",
        "    \"unsloth/Phi-3-mini-4k-instruct\",\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",\n",
        "]"
      ],
      "metadata": {
        "id": "BtDUqHslAgCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Formatando o Dataset de produtos"
      ],
      "metadata": {
        "id": "pOZJA4fsA-fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset_into_model_input(data):\n",
        "    # Inicializando as listas para armazenar os dados\n",
        "    instructions = []\n",
        "    inputs = []\n",
        "    outputs = []\n",
        "\n",
        "    # Alterando a formatação para título e descrição\n",
        "    for example in data:\n",
        "        title = example['title']\n",
        "        content = example['content']\n",
        "        instruction = \"Descreva o produto de forma estilizada.\"\n",
        "\n",
        "        instructions.append(instruction)\n",
        "        inputs.append(title)\n",
        "        outputs.append(content)\n",
        "\n",
        "    # Criando o dicionário final\n",
        "    formatted_data = {\n",
        "        \"instruction\": instructions,\n",
        "        \"input\": inputs,\n",
        "        \"output\": outputs\n",
        "    }\n",
        "\n",
        "    # Salvando o resultado em um arquivo JSON (caso necessário)\n",
        "    formatted_json_path = \"/content/drive/MyDrive/trn.json/formatted_amazon_product_data.json\"\n",
        "    with open(formatted_json_path, 'w') as output_file:\n",
        "        json.dump(formatted_data, output_file, indent=4)\n",
        "\n",
        "    print(f\"Dataset formatado salvo em: {formatted_json_path}\")\n",
        "\n",
        "    return formatted_json_path"
      ],
      "metadata": {
        "id": "cCyDkNKABDH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Declarando Constantes e Formatando o Dataset da Amazon"
      ],
      "metadata": {
        "id": "oZe6VdBx-zDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho do arquivo JSON original\n",
        "DATA_PATH = '/content/drive/MyDrive/trn.json/trn.json'\n",
        "\n",
        "# Carregar o dataset do arquivo JSON\n",
        "dataset = load_dataset(\"json\", data_files=DATA_PATH)\n",
        "\n",
        "# Caminho do arquivo CSV que será gerado\n",
        "OUTPUT_PATH_DATASET = format_dataset_into_model_input(dataset['train'] if 'train' in dataset else dataset)\n"
      ],
      "metadata": {
        "id": "Ji2Pi2Aa9VH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o modelo pré treinado"
      ],
      "metadata": {
        "id": "FJpSvVneFv3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-70B\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit\n",
        ")"
      ],
      "metadata": {
        "id": "as-bnxo5FzJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando a inferência do modelo ainda não ajustado com Fine Tuning"
      ],
      "metadata": {
        "id": "bQ6zQgS3lLkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "DK00At1gooxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função para testar o modelo"
      ],
      "metadata": {
        "id": "jXv0pofSQs7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_description(title):\n",
        "    input_text = f\"Descreva o produto de forma estilizada.\\nTítulo: {title}\\nDescrição:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128)\n",
        "    description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return description"
      ],
      "metadata": {
        "id": "CKrLawBPQyCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando o modelo sem fine tuning"
      ],
      "metadata": {
        "id": "2-S7TjGRr57M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Smartphone Android 64GB\"\n",
        "description = generate_description(title)\n",
        "print(f\"Título: {title}\\nDescrição: {description}\")"
      ],
      "metadata": {
        "id": "5rODPsWSsC9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ajustes finos do LoRA"
      ],
      "metadata": {
        "id": "wAyGqHg9HFIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")"
      ],
      "metadata": {
        "id": "wq2AVQGEF7Tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt para a descrição dos produtos"
      ],
      "metadata": {
        "id": "BiGjHinzHceb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Abaixo está uma instrução que descreve a tarefa, juntamente com um título que fornece mais contexto. Escreva uma resposta que conclua a descrição de forma apropriada.\n",
        "\n",
        "### Instrução:\n",
        "{}\n",
        "\n",
        "### Título:\n",
        "{}\n",
        "\n",
        "### Descrição:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "LMj6sofYHim_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função para formatar o Prompt"
      ],
      "metadata": {
        "id": "1AFYQdtiIB1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(data):\n",
        "    instructions = data[\"instruction\"]\n",
        "    inputs = dataset[\"input\"]\n",
        "    outputs = data[\"output\"]\n",
        "    texts = []\n",
        "\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "\n",
        "    return {\"text\": texts}"
      ],
      "metadata": {
        "id": "O6rKiNK5H3ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregar o Dataset"
      ],
      "metadata": {
        "id": "DS1dVsp2Su8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=OUTPUT_PATH_DATASET)\n",
        "formatted_dataset = dataset['train'].map(formatting_prompts_func, batched=True)"
      ],
      "metadata": {
        "id": "lscUwyCVSxCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset"
      ],
      "metadata": {
        "id": "2N-y58yJVO8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]"
      ],
      "metadata": {
        "id": "XEPKO3SiePLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configurações do Trainer"
      ],
      "metadata": {
        "id": "4xzY8bv8TLaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=formatted_dataset,  # Usando o dataset formatado e o split 'train'\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "tjsb6bhBTOnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando o Modelo"
      ],
      "metadata": {
        "id": "TLN2JUNZajb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "id": "4e1Hc9AmalyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salvando o Modelo"
      ],
      "metadata": {
        "id": "ruZGsCyCbWTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo ajustado\n",
        "model.save_pretrained(\"/content/drive/MyDrive/trn.json/lora_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/trn.json/lora_model\")"
      ],
      "metadata": {
        "id": "BoHSF7pIbbDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reutilizando o modelo já treinado"
      ],
      "metadata": {
        "id": "-UALVVpOPi5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho para o modelo salvo\n",
        "model_path = \"/content/drive/MyDrive/trn.json/lora_model\"\n",
        "\n",
        "# Carregar o modelo e o tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(model_path)\n",
        "\n",
        "# Preparar o modelo para inferência\n",
        "FastLanguageModel.for_inference(model)"
      ],
      "metadata": {
        "id": "rhB5KgThPm-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando o modelo com fine tuning"
      ],
      "metadata": {
        "id": "5okShgmproL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title = \"Smartphone Android 64GB\"\n",
        "description = generate_description(title)\n",
        "print(f\"Título: {title}\\nDescrição: {description}\")"
      ],
      "metadata": {
        "id": "DQajFZoLrwBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}